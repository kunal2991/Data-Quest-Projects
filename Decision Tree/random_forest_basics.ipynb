{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education_num  \\\n",
      "0   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "1   38            Private  215646     HS-grad              9   \n",
      "2   53            Private  234721        11th              7   \n",
      "3   28            Private  338409   Bachelors             13   \n",
      "4   37            Private  284582     Masters             14   \n",
      "\n",
      "        marital_status          occupation    relationship    race      sex  \\\n",
      "0   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "1             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "2   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "3   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "4   Married-civ-spouse     Exec-managerial            Wife   White   Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week  native_country high_income  \n",
      "0             0             0              13   United-States       <=50K  \n",
      "1             0             0              40   United-States       <=50K  \n",
      "2             0             0              40   United-States       <=50K  \n",
      "3             0             0              40            Cuba       <=50K  \n",
      "4             0             0              40   United-States       <=50K  \n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "income = pandas.read_csv('income.csv',index_col=False)\n",
    "columns = [['age','workclass','fnlwgt','education','education_num','marital_status','occupation','relationship','race','sex','capital_gain','capital_loss','hours_per_week','native_country','high_income']]\n",
    "income.columns = columns\n",
    "print(income.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6\n",
      "1    4\n",
      "2    4\n",
      "3    4\n",
      "4    4\n",
      "Name: workclass, dtype: int8\n"
     ]
    }
   ],
   "source": [
    "#Converting categorical variables in income to codes using Categorical.from_array\n",
    "\n",
    "col = pandas.Categorical.from_array(income['workclass'])\n",
    "income['workclass'] = col.codes\n",
    "print(income['workclass'].head(5))\n",
    "for name in [\"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\", \"high_income\"]:\n",
    "    col = pandas.Categorical.from_array(income[name])\n",
    "    income[name] = col.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788010055233\n",
      "0.773232669946\n"
     ]
    }
   ],
   "source": [
    "# Working with Ensembles.\n",
    "#First, we create 2 different models with varying depth controlling parameters and calculate their roc error values.\n",
    "\n",
    "import math\n",
    "np.random.seed(1)\n",
    "income = income.reindex(np.random.permutation(income.index))\n",
    "\n",
    "train_max_row = math.floor(income.shape[0] * .8)\n",
    "\n",
    "train = income[:train_max_row]\n",
    "test = income[train_max_row:]\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=75)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "clf2 = DecisionTreeClassifier(random_state=1, max_depth=6)\n",
    "clf2.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "predictions = clf.predict(test[columns])\n",
    "error = roc_auc_score(predictions, test['high_income'])\n",
    "print(error)\n",
    "\n",
    "predictions = clf2.predict(test[columns])\n",
    "error = roc_auc_score(predictions, test['high_income'])\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above values, we can see the roc error value for the 2 models with some minor variations in the depth controlling parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.791496726317\n"
     ]
    }
   ],
   "source": [
    "#Combining predictions using predict_proba\n",
    "\n",
    "predictions = clf.predict_proba(test[columns])[:,1]\n",
    "predictions2 = clf2.predict_proba(test[columns])[:,1]\n",
    "\n",
    "mean = (predictions + predictions2)/2\n",
    "mean = np.round(mean)\n",
    "\n",
    "error = roc_auc_score(mean, test['high_income'])\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above value we can see that the combined predictions for the models is better than the individual scores. Hence ensembling will help us in achieving more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795120093815\n"
     ]
    }
   ],
   "source": [
    "# Introducing Bagging as a technique to introduce variation in the DTs to gain better AUC score.\n",
    "\n",
    "tree_count = 10 #Bagging for 10 trees\n",
    "\n",
    "bag_proportion = 0.6 #Each bag will have 60% of the number of original rows\n",
    "\n",
    "predictions = []\n",
    "for i in range(tree_count):\n",
    "        bag = train.sample(frac=bag_proportion, replace=True, random_state=i)\n",
    "        clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=75)\n",
    "        clf.fit(bag[columns], bag[\"high_income\"])\n",
    "        predictions.append(clf.predict_proba(test[columns])[:,1])\n",
    "\n",
    "mean = sum(predictions) / 10\n",
    "mean = np.round(mean)\n",
    "\n",
    "error = roc_auc_score(mean, test['high_income'])\n",
    "print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that by introducing variations by Bagging in 10 DTs instead of 1, we have managed to improve the AUC score over the single DT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'column': 'employment', 'median': 4.5, 'left': {'column': 'age', 'median': 25.0, 'left': {'column': 'age', 'median': 22.5, 'left': {'label': 0, 'number': 4}, 'number': 3, 'right': {'label': 1, 'number': 5}}, 'number': 2, 'right': {'label': 0, 'number': 6}}, 'number': 1, 'right': {'column': 'age', 'median': 40.0, 'left': {'column': 'age', 'median': 37.5, 'left': {'label': 1, 'number': 9}, 'number': 8, 'right': {'label': 0, 'number': 10}}, 'number': 7, 'right': {'label': 1, 'number': 11}}}\n",
      "{'column': 'age', 'median': 37.5, 'left': {'column': 'employment', 'median': 4.0, 'left': {'column': 'age', 'median': 22.5, 'left': {'label': 0, 'number': 15}, 'number': 14, 'right': {'label': 1, 'number': 16}}, 'number': 13, 'right': {'label': 1, 'number': 17}}, 'number': 12, 'right': {'column': 'age', 'median': 55.0, 'left': {'column': 'age', 'median': 47.5, 'left': {'label': 0, 'number': 20}, 'number': 19, 'right': {'label': 1, 'number': 21}}, 'number': 18, 'right': {'label': 0, 'number': 22}}}\n"
     ]
    }
   ],
   "source": [
    "# Selecting Random Features i.e selecting a random sample of features from the data, computing the Information Gain for each feature and then selecting the one with the highest Gain.\n",
    "\n",
    "data = pandas.DataFrame([\n",
    "    [0,4,20,0],\n",
    "    [0,4,60,2],\n",
    "    [0,5,40,1],\n",
    "    [1,4,25,1],\n",
    "    [1,5,35,2],\n",
    "    [1,5,55,1]\n",
    "    ])\n",
    "data.columns = [\"high_income\", \"employment\", \"age\", \"marital_status\"]\n",
    "\n",
    "def calc_information_gain(data, split_name, target_name):\n",
    "    original_entropy = calc_entropy(data[target_name])\n",
    "    \n",
    "    column = data[split_name]\n",
    "    median = column.median()\n",
    "    \n",
    "    left_split = data[column <= median]\n",
    "    right_split = data[column > median]\n",
    "    \n",
    "    to_subtract = 0\n",
    "    for subset in [left_split, right_split]:\n",
    "        prob = (subset.shape[0] / data.shape[0]) \n",
    "        to_subtract += prob * calc_entropy(subset[target_name])\n",
    "    \n",
    "    return original_entropy - to_subtract\n",
    "\n",
    "\n",
    "def calc_entropy(column):\n",
    "    counts = np.bincount(column)\n",
    "    probabilities = counts / len(column)\n",
    "    entropy = 0\n",
    "    for prob in probabilities:\n",
    "        if prob > 0:\n",
    "            entropy = entropy + prob * math.log(prob,2)\n",
    "    return -entropy\n",
    "\n",
    "\n",
    "# Set a random seed to make results reproducible.\n",
    "np.random.seed(1)\n",
    "\n",
    "# The dictionary to store our tree.\n",
    "tree = {}\n",
    "nodes = []\n",
    "\n",
    "# The function to find the column to split on.\n",
    "def find_best_column(data, target_name, columns):\n",
    "    information_gains = []\n",
    "    \n",
    "    # Insert your code here.\n",
    "    \n",
    "    for col in columns:\n",
    "        information_gain = calc_information_gain(data, col, \"high_income\")\n",
    "        information_gains.append(information_gain)\n",
    "\n",
    "    # Find the name of the column with the highest gain.\n",
    "    highest_gain_index = information_gains.index(max(information_gains))\n",
    "    highest_gain = columns[highest_gain_index]\n",
    "    return highest_gain\n",
    "\n",
    "# The function to construct an id3 decision tree.\n",
    "def id3(data, target, columns, tree):\n",
    "    unique_targets = pandas.unique(data[target])\n",
    "    nodes.append(len(nodes) + 1)\n",
    "    tree[\"number\"] = nodes[-1]\n",
    "\n",
    "    if len(unique_targets) == 1:\n",
    "        if 0 in unique_targets:\n",
    "            tree[\"label\"] = 0\n",
    "        elif 1 in unique_targets:\n",
    "            tree[\"label\"] = 1\n",
    "        return\n",
    "    \n",
    "    best_column = find_best_column(data, target, columns)\n",
    "    column_median = data[best_column].median()\n",
    "    \n",
    "    tree[\"column\"] = best_column\n",
    "    tree[\"median\"] = column_median\n",
    "    \n",
    "    left_split = data[data[best_column] <= column_median]\n",
    "    right_split = data[data[best_column] > column_median]\n",
    "    split_dict = [[\"left\", left_split], [\"right\", right_split]]\n",
    "    \n",
    "    for name, split in split_dict:\n",
    "        tree[name] = {}\n",
    "        id3(split, target, columns, tree[name])\n",
    "\n",
    "\n",
    "# Run the id3 algorithm on our dataset and print the resulting tree.\n",
    "id3(data, \"high_income\", [\"employment\", \"age\", \"marital_status\"], tree)\n",
    "print(tree)\n",
    "def find_best_column(data, target_name, columns):\n",
    "    information_gains = []\n",
    "    \n",
    "    # Select two columns randomly.\n",
    "    cols = np.random.choice(columns, 2)\n",
    "    \n",
    "    for col in cols:\n",
    "        information_gain = calc_information_gain(data, col, \"high_income\")\n",
    "        information_gains.append(information_gain)\n",
    "\n",
    "    highest_gain_index = information_gains.index(max(information_gains))\n",
    "    \n",
    "    # Get the highest gain by indexing cols.\n",
    "    highest_gain = cols[highest_gain_index]\n",
    "    \n",
    "    return highest_gain\n",
    "\n",
    "id3(data, \"high_income\", [\"employment\", \"age\", \"marital_status\"], tree)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792676621435\n"
     ]
    }
   ],
   "source": [
    "# Using the Scikit-Learn package to do the same.\n",
    "\n",
    "tree_count = 10\n",
    "\n",
    "# Each \"bag\" will have 70% of the number of original rows.\n",
    "bag_proportion = .7\n",
    "\n",
    "predictions = []\n",
    "for i in range(tree_count):\n",
    "    # We select 80% of the rows from train, sampling with replacement.\n",
    "    # We set a random state to ensure we'll be able to replicate our results.\n",
    "    # We set it to i instead of a fixed value so we don't get the same sample every time.\n",
    "    bag = train.sample(frac=bag_proportion, replace=True, random_state=i)\n",
    "    \n",
    "    # Fit a decision tree model to the \"bag\".\n",
    "    clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=75, splitter='random', max_features='auto')\n",
    "    clf.fit(bag[columns], bag[\"high_income\"])\n",
    "    \n",
    "    # Using the model, make predictions on the test data.\n",
    "    predictions.append(clf.predict_proba(test[columns])[:,1])\n",
    "\n",
    "combined = np.sum(predictions, axis=0) / 10\n",
    "rounded = np.round(combined)\n",
    "\n",
    "print(roc_auc_score(rounded, test[\"high_income\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.791664009288\n"
     ]
    }
   ],
   "source": [
    "# Using RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=1, min_samples_leaf=75)\n",
    "clf.fit(train[columns], train['high_income'])\n",
    "\n",
    "predictions = clf.predict(test[columns])\n",
    "\n",
    "error = roc_auc_score(predictions, test['high_income'])\n",
    "print(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
