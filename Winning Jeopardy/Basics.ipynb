{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Show Number    Air Date      Round                         Category  Value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
      "\n",
      "                                            Question      Answer  \n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
      "2  The city of Yuma in this state has a record av...     Arizona  \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  \n",
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value', ' Question', ' Answer'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Reading the dataset \n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "print(jeopardy.head(5))\n",
    "print(jeopardy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question', 'Answer'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "fixed_columns = ['Show Number','Air Date','Round','Category','Value','Question','Answer']\n",
    "jeopardy.columns= fixed_columns\n",
    "print(jeopardy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating a function that normalizes text\n",
    "import re\n",
    "def normalize_text(string):\n",
    "    string = string.lower()\n",
    "    string = re.sub(\"[^A-Za-z0-9\\s]\", \"\", string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize_text)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a function that normalizes the VALUE column \n",
    "def normalize_values(string):\n",
    "    string = re.sub(\"[^A-Za-z0-9\\s]\", \"\", string)\n",
    "    try:\n",
    "        string = int(string)\n",
    "    except Exception:\n",
    "        string = 0\n",
    "    return string\n",
    "\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(normalize_values)\n",
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating a function to determine general trends\n",
    "def find_prediction(row):\n",
    "    split_answer = row['clean_answer'].split(' ')\n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    match_count = 0\n",
    "    the = 'the'\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if(len(split_answer)==0):\n",
    "        return 0\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "        else:\n",
    "            pass\n",
    "    return(match_count/len(split_answer))\n",
    "\n",
    "answer_in_question = jeopardy.apply(find_prediction,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0604932570693\n"
     ]
    }
   ],
   "source": [
    "jeopardy['answer_in_question'] = answer_in_question\n",
    "mean = jeopardy['answer_in_question'].mean()\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the mean value given above, we can see that only 6% of the time we can deduce the answer from the question. The value is very low to be used as a method for predicting the answer for Jeopardy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.690873731567\n"
     ]
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "for i, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    split_question_updated = []\n",
    "    for item in split_question:\n",
    "        if(len(item)>5):\n",
    "            split_question_updated.append(item)\n",
    "        else:\n",
    "            pass\n",
    "    match_count = 0\n",
    "    for item in split_question_updated:\n",
    "        if item in terms_used:\n",
    "            match_count += 1\n",
    "    for item in split_question_updated:\n",
    "        terms_used.add(item)\n",
    "    if(len(split_question_updated)>0):\n",
    "        match_count = match_count / len(split_question_updated)\n",
    "    question_overlap.append(match_count)\n",
    "jeopardy['question_overlap'] = question_overlap\n",
    "print(jeopardy['question_overlap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the abover value, we can see that about 70% of the questions are repeated from the older ones, although this might be a little exaggerated since the dataset that we are operating on is only 10% of the original full Jeopardy question dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_value(row):\n",
    "    value = 0\n",
    "    if row[\"clean_value\"] > 800:\n",
    "        value = 1\n",
    "    return value\n",
    "\n",
    "jeopardy[\"high_value\"] = jeopardy.apply(determine_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 4), (0, 1), (0, 1), (0, 2), (1, 0)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_usage(term):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        if term in row[\"clean_question\"].split(\" \"):\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "comparison_terms = list(terms_used)[:5]\n",
    "observed_expected = []\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(count_usage(term))\n",
    "\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.607851384507536, 0.20479409439225948), (0.40196284612688399, 0.52607729857054686), (0.40196284612688399, 0.52607729857054686), (0.80392569225376798, 0.36992223780795708), (2.4877921171956752, 0.11473257634454047)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "high_value_1_count = 0\n",
    "high_value_0_count = 0\n",
    "high_value_1_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "high_value_0_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "chi_squared = []\n",
    "for row in observed_expected:\n",
    "    total = sum(row)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    exp_high_value = total_prop * high_value_1_count\n",
    "    exp_low_value = total_prop * high_value_0_count\n",
    "    observed_values = np.array([row[0],row[1]])\n",
    "    expected_values = np.array([exp_high_value,exp_low_value])\n",
    "    chi_squared.append(chisquare(observed_values,expected_values))\n",
    "    \n",
    "print(chi_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the chi-squared test done above, none of the p-values are less than 0.05, meaning that we can easily say that our question in deducing that studying questions that pertain to high value questions instead of low value questions will help us to earn more money is not true and also that we need to look at other values too."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
