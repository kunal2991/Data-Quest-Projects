{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18  8    307  130  3504    12  70  1 chevrolet chevelle malibu\n",
      "0  15.0  8  350.0  165  3693  11.5  70  1         buick skylark 320\n",
      "1  18.0  8  318.0  150  3436  11.0  70  1        plymouth satellite\n",
      "2  16.0  8  304.0  150  3433  12.0  70  1             amc rebel sst\n",
      "3  17.0  8  302.0  140  3449  10.5  70  1               ford torino\n",
      "4  15.0  8  429.0  198  4341  10.0  70  1          ford galaxie 500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "cars = pd.read_csv('auto-mpg.csv')\n",
    "print(cars.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset. Note that there are no column names. Next step is to add them manually. This happens because sometimes the data is used from a .txt and then converted to a .csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  year  \\\n",
      "0  15.0          8         350.0        165    3693          11.5    70   \n",
      "1  18.0          8         318.0        150    3436          11.0    70   \n",
      "2  16.0          8         304.0        150    3433          12.0    70   \n",
      "3  17.0          8         302.0        140    3449          10.5    70   \n",
      "4  15.0          8         429.0        198    4341          10.0    70   \n",
      "\n",
      "   origin            car_name  \n",
      "0       1   buick skylark 320  \n",
      "1       1  plymouth satellite  \n",
      "2       1       amc rebel sst  \n",
      "3       1         ford torino  \n",
      "4       1    ford galaxie 500  \n"
     ]
    }
   ],
   "source": [
    "cars.columns = ['mpg','cylinders','displacement','horsepower','weight','acceleration','year','origin','car_name']\n",
    "print(cars.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2]\n"
     ]
    }
   ],
   "source": [
    "unique_regions = cars['origin'].unique()\n",
    "print(unique_regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem statement or our aim here is to predict or classify the \"origin\" of the vehicle depending on the other given parameters.\n",
    "As you can see there are 3 unique regions:\n",
    "1. 1-->North America\n",
    "2. 2-->Europe\n",
    "3. 3-->Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  year  \\\n",
      "0  15.0          8         350.0        165    3693          11.5    70   \n",
      "1  18.0          8         318.0        150    3436          11.0    70   \n",
      "2  16.0          8         304.0        150    3433          12.0    70   \n",
      "3  17.0          8         302.0        140    3449          10.5    70   \n",
      "4  15.0          8         429.0        198    4341          10.0    70   \n",
      "\n",
      "   origin            car_name  cyl_3  cyl_4  cyl_5  cyl_6  cyl_8  \n",
      "0       1   buick skylark 320    0.0    0.0    0.0    0.0    1.0  \n",
      "1       1  plymouth satellite    0.0    0.0    0.0    0.0    1.0  \n",
      "2       1       amc rebel sst    0.0    0.0    0.0    0.0    1.0  \n",
      "3       1         ford torino    0.0    0.0    0.0    0.0    1.0  \n",
      "4       1    ford galaxie 500    0.0    0.0    0.0    0.0    1.0  \n",
      "    mpg  displacement horsepower  weight  acceleration  origin  \\\n",
      "0  15.0         350.0        165    3693          11.5       1   \n",
      "1  18.0         318.0        150    3436          11.0       1   \n",
      "2  16.0         304.0        150    3433          12.0       1   \n",
      "3  17.0         302.0        140    3449          10.5       1   \n",
      "4  15.0         429.0        198    4341          10.0       1   \n",
      "\n",
      "             car_name  cyl_3  cyl_4  cyl_5   ...     year_73  year_74  \\\n",
      "0   buick skylark 320    0.0    0.0    0.0   ...         0.0      0.0   \n",
      "1  plymouth satellite    0.0    0.0    0.0   ...         0.0      0.0   \n",
      "2       amc rebel sst    0.0    0.0    0.0   ...         0.0      0.0   \n",
      "3         ford torino    0.0    0.0    0.0   ...         0.0      0.0   \n",
      "4    ford galaxie 500    0.0    0.0    0.0   ...         0.0      0.0   \n",
      "\n",
      "   year_75  year_76  year_77  year_78  year_79  year_80  year_81  year_82  \n",
      "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "dummy_cylinders = pd.get_dummies(cars[\"cylinders\"], prefix=\"cyl\")\n",
    "cars = pd.concat([cars, dummy_cylinders], axis=1)\n",
    "print(cars.head())\n",
    "\n",
    "dummy_years = pd.get_dummies(cars['year'], prefix='year')\n",
    "cars = pd.concat([cars, dummy_years], axis=1)\n",
    "cars.drop(['year','cylinders'],inplace=True,axis=1)\n",
    "print(cars.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create numeric representation of categorical values yourself. For this dataset, categorical variables exist in three columns, cylinders, year, and origin. The cylinders and year columns must be converted to numeric values so we can use them to predict label origin. Even though the column year is a number, weâ€™re going to treat them like categories. The year 71 is unlikely to relate to the year 70 in the same way those two numbers do numerically, but rather just as two different labels. In these instances, it is always safer to treat discrete values as categorical variables.\n",
    "\n",
    "We must use dummy variables for columns containing categorical values. Whenever we have more than 2 categories, we need to create more columns to represent the categories. Since we have 5 different categories of cylinders, we could use 3, 4, 5, 6, and 8 to represent the different categories. We can split the column into separate binary columns:\n",
    "\n",
    "cyl_3 -- Does the car have 3 cylinders? 0 if False, 1 if True.\n",
    "cyl_4 -- Does the car have 4 cylinders? 0 if False, 1 if True.\n",
    "cyl_5 -- Does the car have 5 cylinders? 0 if False, 1 if True.\n",
    "cyl_6 -- Does the car have 6 cylinders? 0 if False, 1 if True.\n",
    "cyl_8 --Does the car have 8 cylinders? 0 if False, 1 if True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_rows = np.random.permutation(cars.index)\n",
    "shuffled_cars = cars.iloc[shuffled_rows]\n",
    "\n",
    "highest_train_row = int(cars.shape[0] * .70)\n",
    "train = shuffled_cars.iloc[0:highest_train_row]\n",
    "test = shuffled_cars.iloc[highest_train_row:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning 70% data for training and 30% for testing. We now have to train a Multiclass Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "unique_regions.sort()\n",
    "models = {}\n",
    "features = [c for c in train.columns if c.startswith('cyl') or c.startswith('year')]\n",
    "\n",
    "for origin in unique_regions:\n",
    "    model = LogisticRegression()\n",
    "    X_train = train[features]\n",
    "    y_train = train['origin'] == origin\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    models[origin] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the one-vs-all approach, we're essentially converting an n-class (in our case n is 3) classification problem into n binary classification problems. For our case, we'll need to train 3 models:\n",
    "\n",
    "A model where all cars built in North America are considered Positive (1) and those built in Europe and Asia are considered Negative (0).\n",
    "A model where all cars built in Europe are considered Positive (1) and those built in North America and Asia are considered Negative (0).\n",
    "A model where all cars built in Asia are labeled Positive (1) and those built in North America and Europe are considered Negative (0).\n",
    "Each of these models is a binary classification model that will return a probability between 0 and 1. When we apply this model on new data, a probability value will be returned from each model (3 total). For each observation, we choose the label corresponding to the model that predicted the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_probs = pd.DataFrame(columns = unique_regions)\n",
    "\n",
    "for origin in unique_regions:\n",
    "    testing_probs[origin] = models[origin].predict_proba(test[features])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model for each category, we can run our test dataset through the models and evaluate how well they performed.\n",
    "\n",
    "Now that we trained the models and computed the probabilities in each origin we can classify each observation. To classify each observation we want to select the origin with the highest probability of classification for that observation.\n",
    "\n",
    "While each column in our dataframe testing_probs represents an origin we just need to choose the one with the largest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      2\n",
      "5      1\n",
      "6      2\n",
      "7      1\n",
      "8      2\n",
      "9      1\n",
      "10     1\n",
      "11     1\n",
      "12     1\n",
      "13     1\n",
      "14     1\n",
      "15     1\n",
      "16     1\n",
      "17     1\n",
      "18     1\n",
      "19     1\n",
      "20     1\n",
      "21     1\n",
      "22     3\n",
      "23     2\n",
      "24     1\n",
      "25     1\n",
      "26     3\n",
      "27     1\n",
      "28     3\n",
      "29     2\n",
      "      ..\n",
      "90     1\n",
      "91     3\n",
      "92     1\n",
      "93     1\n",
      "94     1\n",
      "95     1\n",
      "96     1\n",
      "97     1\n",
      "98     3\n",
      "99     2\n",
      "100    1\n",
      "101    1\n",
      "102    1\n",
      "103    3\n",
      "104    1\n",
      "105    1\n",
      "106    1\n",
      "107    1\n",
      "108    1\n",
      "109    3\n",
      "110    1\n",
      "111    1\n",
      "112    2\n",
      "113    1\n",
      "114    1\n",
      "115    2\n",
      "116    1\n",
      "117    1\n",
      "118    1\n",
      "119    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "predicted_origins = testing_probs.idxmax(axis = 1)\n",
    "print(predicted_origins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work out the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunalbarde/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "test['predicted_origins'] = predicted_origins\n",
    "correct_predictions = test[test['origin'] == test['predicted_origins']]\n",
    "accuracy = len(correct_predictions) / len(test)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
